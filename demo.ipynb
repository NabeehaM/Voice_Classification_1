{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:15:43.529164400Z",
     "start_time": "2023-09-14T19:15:43.426889100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helllo Jupyter\n"
     ]
    }
   ],
   "source": [
    "print(\"Helllo Jupyter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Downloading tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "     ------------------------------------ 276.5/276.5 MB 967.1 kB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 KB 2.5 MB/s eta 0:00:00\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.8/440.8 KB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 KB 1.5 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (58.1.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.58.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.9.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.24.3-cp39-cp39-win_amd64.whl (430 kB)\n",
      "     -------------------------------------- 430.5/430.5 KB 1.7 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22\n",
      "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 14.9/14.9 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp39-cp39-win_amd64.whl (36 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 1.5 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 KB 1.2 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.41.2-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.2/94.2 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.4/181.4 KB 1.6 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "     ------------------------------------ 242.2/242.2 KB 707.2 kB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting urllib3<2.0\n",
      "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "     -------------------------------------- 143.1/143.1 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.3/181.3 KB 1.8 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.16.2)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.9/83.9 KB 1.6 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 KB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, wheel, werkzeug, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, keras, grpcio, google-pasta, gast, cachetools, absl-py, rsa, pyasn1-modules, opt-einsum, markdown, h5py, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.0.4\n",
      "    Uninstalling urllib3-2.0.4:\n",
      "      Successfully uninstalled urllib3-2.0.4\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.23.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.58.0 h5py-3.9.0 keras-2.13.1 libclang-16.0.6 markdown-3.4.4 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.5.0 urllib3-1.26.16 werkzeug-2.3.7 wheel-0.41.2 wrapt-1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "filelock 3.12.3 requires typing-extensions>=4.7.1; python_version < \"3.11\", but you have typing-extensions 4.5.0 which is incompatible.\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T14:46:12.407571300Z",
     "start_time": "2023-09-14T14:38:56.633474500Z"
    }
   },
   "id": "9ac64dc8116f42c5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio\n",
    "import subprocess"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:02.103447900Z",
     "start_time": "2023-09-14T19:15:57.394051400Z"
    }
   },
   "id": "7beaac73ea40780b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_directory = \"./datasets\"\n",
    "audio_folder = \"audio\"\n",
    "noise_folder = \"_background_noise_\"\n",
    "\n",
    "audio_path = os.path.join(data_directory, audio_folder)\n",
    "noise_path = os.path.join(data_directory, noise_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:03.238164700Z",
     "start_time": "2023-09-14T19:16:03.206919600Z"
    }
   },
   "id": "7d592aebec8425e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'./datasets\\\\audio'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:04.748547600Z",
     "start_time": "2023-09-14T19:16:04.702448200Z"
    }
   },
   "id": "e6d610270ee1ddf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "valid_split = 0.1\n",
    "\n",
    "shuffle_seed = 43\n",
    "\n",
    "sample_rate = 16000\n",
    "\n",
    "scale = 0.5\n",
    "\n",
    "batch_size = 40 #changed from 127\n",
    "\n",
    "epochs = 8 #changed from 15"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:05.422485500Z",
     "start_time": "2023-09-14T19:16:05.391246200Z"
    }
   },
   "id": "1d308404c771949e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for folder in os.listdir(data_directory):\n",
    "    if os.path.isdir(os.path.join(data_directory, folder)):\n",
    "        if folder in [audio_folder, noise_folder]:\n",
    "            \n",
    "            continue\n",
    "        elif folder in [\"other\", \"_background_noise_\"]:\n",
    "            \n",
    "            shutil.move(\n",
    "                os.path.join(data_directory, folder),\n",
    "                os.path.join(noise_path, folder),\n",
    "            )\n",
    "        else:\n",
    "            shutil.move(\n",
    "                os.path.join(data_directory, folder),\n",
    "                os.path.join(audio_path, folder),\n",
    "            )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:07.454128300Z",
     "start_time": "2023-09-14T19:16:07.407254100Z"
    }
   },
   "id": "41278b680f85d40"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "noise_paths = []\n",
    "for subdir in os.listdir(noise_path):\n",
    "    subdir_path = Path(noise_path) / subdir\n",
    "    if os.path.isdir(subdir_path):\n",
    "        noise_paths += [\n",
    "            os.path.join(subdir_path, filepath)\n",
    "            for filepath in os.listdir(subdir_path)\n",
    "            if filepath.endswith(\".wav\")\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:08.437694900Z",
     "start_time": "2023-09-14T19:16:08.406449200Z"
    }
   },
   "id": "b665208ca72ac841"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['datasets\\\\_background_noise_\\\\other\\\\exercise_bike.wav',\n 'datasets\\\\_background_noise_\\\\other\\\\pink_noise.wav']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_paths"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:09.433461400Z",
     "start_time": "2023-09-14T19:16:09.402171800Z"
    }
   },
   "id": "a173b735e7ba79c4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "command = (\n",
    "    \"for dir in `ls -1 \" + noise_path + \"`; do \"\n",
    "    \"for file in `ls -1 \" + noise_path + \"/$dir/*.wav`; do \"\n",
    "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
    "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
    "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
    "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
    "    \"-i $file -ar 16000 temp.wav; \"\n",
    "    \"mv temp.wav $file; \"\n",
    "    \"fi; done; done\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:10.309114900Z",
     "start_time": "2023-09-14T19:16:10.279975400Z"
    }
   },
   "id": "2021fc21c6d08ca4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate for datasets\\_background_noise_\\other\\exercise_bike.wav is incorrect\n",
      "Sampling rate for datasets\\_background_noise_\\other\\pink_noise.wav is incorrect\n"
     ]
    }
   ],
   "source": [
    "os.system(command)\n",
    "def load_noise_sample(path):\n",
    "    sample, sampling_rate = tf.audio.decode_wav(\n",
    "        tf.io.read_file(path), desired_channels=1\n",
    "    )\n",
    "    if sampling_rate == sample_rate:\n",
    "        slices = int(sample.shape[0] / sample_rate)\n",
    "        sample = tf.split(sample[: slices * sample_rate], slices)\n",
    "        return sample\n",
    "    else:\n",
    "        print(\"Sampling rate for\",path, \"is incorrect\")\n",
    "        return None\n",
    "\n",
    "\n",
    "noises = []\n",
    "for path in noise_paths:\n",
    "    sample = load_noise_sample(path)\n",
    "    if sample:\n",
    "        noises.extend(sample)\n",
    "noises = tf.stack(noises)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:11.259548200Z",
     "start_time": "2023-09-14T19:16:11.080571Z"
    }
   },
   "id": "1956885fc64a4d43"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def paths_and_labels_to_dataset(audio_paths, labels):\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
    "    audio_ds = path_ds.map(lambda x: path_to_audio(x))\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "    return tf.data.Dataset.zip((audio_ds, label_ds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:12.017561300Z",
     "start_time": "2023-09-14T19:16:11.986312100Z"
    }
   },
   "id": "fe4b90d46d2a0311"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def path_to_audio(path):\n",
    "    audio = tf.io.read_file(path)\n",
    "    audio, _ = tf.audio.decode_wav(audio, 1, sample_rate)\n",
    "    return audio"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:13.383609600Z",
     "start_time": "2023-09-14T19:16:13.351949900Z"
    }
   },
   "id": "87e2f5b15a10accd"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def add_noise(audio, noises=None, scale=0.5):\n",
    "    if noises is not None:\n",
    "        tf_rnd = tf.random.uniform(\n",
    "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
    "        )\n",
    "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
    "\n",
    "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
    "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
    "\n",
    "        audio = audio + noise * prop * scale\n",
    "\n",
    "    return audio"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:14.198948Z",
     "start_time": "2023-09-14T19:16:14.167809300Z"
    }
   },
   "id": "295d254716df5bf8"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def audio_to_fft(audio):\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    fft = tf.signal.fft(\n",
    "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
    "    )\n",
    "    fft = tf.expand_dims(fft, axis=-1)\n",
    "\n",
    "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:14.843573100Z",
     "start_time": "2023-09-14T19:16:14.810523600Z"
    }
   },
   "id": "6b3063379ca793dd"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aleena', 'areeba', 'Benjamin_Netanyau', 'Jens_Stoltenberg', 'Julia_Gillard', 'Magaret_Tarcher', 'nabeeha', 'Nelson_Mandela']\n",
      "Speaker: aleena\n",
      "Speaker: areeba\n",
      "Speaker: Benjamin_Netanyau\n",
      "Speaker: Jens_Stoltenberg\n",
      "Speaker: Julia_Gillard\n",
      "Speaker: Magaret_Tarcher\n",
      "Speaker: nabeeha\n",
      "Speaker: Nelson_Mandela\n"
     ]
    }
   ],
   "source": [
    "class_names = os.listdir(audio_path)\n",
    "print(class_names,)\n",
    "\n",
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Speaker:\",(name))\n",
    "    dir_path = Path(audio_path) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:16.285769400Z",
     "start_time": "2023-09-14T19:16:16.191499200Z"
    }
   },
   "id": "fe5c3fff2d0e6b0c"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Shuffle to generate random data\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(audio_paths)\n",
    "rng = np.random.RandomState(shuffle_seed)\n",
    "rng.shuffle(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:17.088282500Z",
     "start_time": "2023-09-14T19:16:17.072261300Z"
    }
   },
   "id": "2973c73773f068ec"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Split into training and validation\n",
    "num_val_samples = int(valid_split * len(audio_paths))\n",
    "train_audio_paths = audio_paths[:-num_val_samples]\n",
    "train_labels = labels[:-num_val_samples]\n",
    "\n",
    "\n",
    "valid_audio_paths = audio_paths[-num_val_samples:]\n",
    "valid_labels = labels[-num_val_samples:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:18.022703100Z",
     "start_time": "2023-09-14T19:16:17.991455100Z"
    }
   },
   "id": "4a2b6894ff1d3f5f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Create datasets, one for training and the other for validation\n",
    "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
    "train_ds = train_ds.shuffle(buffer_size=batch_size * 8, seed=shuffle_seed).batch(\n",
    "    batch_size\n",
    ")\n",
    "\n",
    "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
    "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=shuffle_seed).batch(32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:19.126799300Z",
     "start_time": "2023-09-14T19:16:18.947501300Z"
    }
   },
   "id": "649924affe29256c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4624\\4097213244.py\", line 3, in None  *\n        lambda x, y: (add_noise(x, noises, scale=scale), y)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4624\\1548865019.py\", line 8, in add_noise  *\n        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n\n    ValueError: Invalid reduction dimension 1 for input with 1 dimensions. for '{{node Max_1}} = Max[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](GatherV2, Max_1/reduction_indices)' with input shapes: [?], [] and with computed input tensors: input[1] = <1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Add noise to the training set\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_ds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43madd_noise\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoises\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexperimental\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAUTOTUNE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Transform audio wave to the frequency domain using `audio_to_fft`\u001B[39;00m\n\u001B[0;32m      8\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m train_ds\u001B[38;5;241m.\u001B[39mmap(\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x, y: (audio_to_fft(x), y), num_parallel_calls\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mAUTOTUNE\n\u001B[0;32m     10\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2278\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[0;32m   2274\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001B[39;00m\n\u001B[0;32m   2275\u001B[0m \u001B[38;5;66;03m# dataset_ops).\u001B[39;00m\n\u001B[0;32m   2276\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[0;32m   2277\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m map_op\n\u001B[1;32m-> 2278\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_v2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2279\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2280\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2281\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2282\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2283\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:40\u001B[0m, in \u001B[0;36m_map_v2\u001B[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[0;32m     37\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _MapDataset(\n\u001B[0;32m     38\u001B[0m       input_dataset, map_func, preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 40\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ParallelMapDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:148\u001B[0m, in \u001B[0;36m_ParallelMapDataset.__init__\u001B[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism \u001B[38;5;241m=\u001B[39m use_inter_op_parallelism\n\u001B[1;32m--> 148\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mstructured_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_legacy_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    154\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deterministic \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:272\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[0;32m    265\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    266\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    267\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    268\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    269\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    270\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[1;32m--> 272\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[0;32m    274\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1189\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1188\u001B[0m   \u001B[38;5;66;03m# Implements GenericFunction.get_concrete_function.\u001B[39;00m\n\u001B[1;32m-> 1189\u001B[0m   concrete \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_concrete_function_garbage_collected(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1190\u001B[0m   concrete\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m concrete\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:1169\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1167\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1168\u001B[0m     initializers \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m-> 1169\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_initializers_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitializers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1170\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize_uninitialized_variables(initializers)\n\u001B[0;32m   1172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[0;32m   1173\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m   1174\u001B[0m   \u001B[38;5;66;03m# version which is guaranteed to never create variables.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:694\u001B[0m, in \u001B[0;36mFunction._initialize\u001B[1;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    692\u001B[0m \u001B[38;5;66;03m# Force the definition of the function for these arguments\u001B[39;00m\n\u001B[0;32m    693\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_variable_creation_fn \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m--> 694\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn    \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    695\u001B[0m     \u001B[38;5;241m.\u001B[39m_get_concrete_function_internal_garbage_collected(\n\u001B[0;32m    696\u001B[0m         \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds))\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvalid_creator_scope\u001B[39m(\u001B[38;5;241m*\u001B[39munused_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munused_kwds):\n\u001B[0;32m    699\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:176\u001B[0m, in \u001B[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    174\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001B[39;00m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m--> 176\u001B[0m   concrete_function, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_concrete_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:171\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_concrete_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m    168\u001B[0m   args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_signature\n\u001B[0;32m    169\u001B[0m   kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:398\u001B[0m, in \u001B[0;36mTracingCompiler._maybe_define_function\u001B[1;34m(self, args, kwargs)\u001B[0m\n\u001B[0;32m    395\u001B[0m args \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39margs\n\u001B[0;32m    396\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m placeholder_bound_args\u001B[38;5;241m.\u001B[39mkwargs\n\u001B[1;32m--> 398\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;66;03m# TODO(b/263520817): Remove access to private attribute.\u001B[39;00m\n\u001B[0;32m    402\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m concrete_function\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mfunction_captures\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:305\u001B[0m, in \u001B[0;36mTracingCompiler._create_concrete_function\u001B[1;34m(self, args, kwargs, func_graph)\u001B[0m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    302\u001B[0m   arg_names \u001B[38;5;241m=\u001B[39m base_arg_names\n\u001B[0;32m    304\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m monomorphic_function\u001B[38;5;241m.\u001B[39mConcreteFunction(\n\u001B[1;32m--> 305\u001B[0m     \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    306\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    307\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_python_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    310\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43marg_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapture_by_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_capture_by_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m,\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function_attributes,\n\u001B[0;32m    316\u001B[0m     spec\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_spec,\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001B[39;00m\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001B[39;00m\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;66;03m# ConcreteFunction.\u001B[39;00m\n\u001B[0;32m    321\u001B[0m     shared_func_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concrete_function\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1055\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[1;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[0m\n\u001B[0;32m   1052\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m   1054\u001B[0m _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[1;32m-> 1055\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m python_func(\u001B[38;5;241m*\u001B[39mfunc_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfunc_kwargs)\n\u001B[0;32m   1057\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[0;32m   1058\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[0;32m   1059\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:597\u001B[0m, in \u001B[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001B[1;34m(*args, **kwds)\u001B[0m\n\u001B[0;32m    593\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m default_graph\u001B[38;5;241m.\u001B[39m_variable_creator_scope(scope, priority\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    594\u001B[0m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[0;32m    595\u001B[0m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[0;32m    596\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[1;32m--> 597\u001B[0m     out \u001B[38;5;241m=\u001B[39m weak_wrapped_fn()\u001B[38;5;241m.\u001B[39m__wrapped__(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    598\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[1;32m--> 238\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    239\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[0;32m    240\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:168\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[1;34m(*args)\u001B[0m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[0;32m    167\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[1;32m--> 168\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    169\u001B[0m ret \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(ret)\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:693\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m--> 693\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m    694\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    695\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[1;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    438\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 439\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    440\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    441\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filep9b_6jn0.py:5\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001B[1;34m(x, y)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner_factory\u001B[39m(ag__):\n\u001B[1;32m----> 5\u001B[0m     tf__lam \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x, y: \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwith_function_scope\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mlscope\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43madd_noise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoises\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlscope\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlscope\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSTD\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf__lam\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\function_wrappers.py:113\u001B[0m, in \u001B[0;36mwith_function_scope\u001B[1;34m(thunk, scope_name, options)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Inline version of the FunctionScope context manager.\"\"\"\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m FunctionScope(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlambda_\u001B[39m\u001B[38;5;124m'\u001B[39m, scope_name, options) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[1;32m--> 113\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mthunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscope\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filep9b_6jn0.py:5\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.<lambda>\u001B[1;34m(lscope)\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner_factory\u001B[39m(ag__):\n\u001B[1;32m----> 5\u001B[0m     tf__lam \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x, y: ag__\u001B[38;5;241m.\u001B[39mwith_function_scope(\u001B[38;5;28;01mlambda\u001B[39;00m lscope: (\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43madd_noise\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnoises\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mscale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscale\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlscope\u001B[49m\u001B[43m)\u001B[49m, y), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlscope\u001B[39m\u001B[38;5;124m'\u001B[39m, ag__\u001B[38;5;241m.\u001B[39mSTD)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf__lam\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    438\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 439\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    440\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    441\u001B[0m     result \u001B[38;5;241m=\u001B[39m converted_f(\u001B[38;5;241m*\u001B[39meffective_args)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegtonbxn2.py:32\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__add_noise\u001B[1;34m(audio, noises, scale)\u001B[0m\n\u001B[0;32m     30\u001B[0m tf_rnd \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtf_rnd\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     31\u001B[0m noise \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnoise\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 32\u001B[0m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mif_stmt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoises\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mif_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43melse_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maudio\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     34\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1269\u001B[0m, in \u001B[0;36mif_stmt\u001B[1;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001B[0m\n\u001B[0;32m   1267\u001B[0m   _tf_if_stmt(cond, body, orelse, get_state, set_state, symbol_names, nouts)\n\u001B[0;32m   1268\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1269\u001B[0m   \u001B[43m_py_if_stmt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morelse\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1322\u001B[0m, in \u001B[0;36m_py_if_stmt\u001B[1;34m(cond, body, orelse)\u001B[0m\n\u001B[0;32m   1320\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_py_if_stmt\u001B[39m(cond, body, orelse):\n\u001B[0;32m   1321\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Overload of if_stmt that executes a Python if statement.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbody\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m cond \u001B[38;5;28;01melse\u001B[39;00m orelse()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegtonbxn2.py:22\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__add_noise.<locals>.if_body\u001B[1;34m()\u001B[0m\n\u001B[0;32m     20\u001B[0m tf_rnd \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39muniform, ((ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mshape, (ag__\u001B[38;5;241m.\u001B[39mld(audio),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)[\u001B[38;5;241m0\u001B[39m],), \u001B[38;5;241m0\u001B[39m, ag__\u001B[38;5;241m.\u001B[39mld(noises)\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]), \u001B[38;5;28mdict\u001B[39m(dtype\u001B[38;5;241m=\u001B[39mag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mint32), fscope)\n\u001B[0;32m     21\u001B[0m noise \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mgather, (ag__\u001B[38;5;241m.\u001B[39mld(noises), ag__\u001B[38;5;241m.\u001B[39mld(tf_rnd)), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), fscope)\n\u001B[1;32m---> 22\u001B[0m prop \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mreduce_max, (ag__\u001B[38;5;241m.\u001B[39mld(audio),), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), fscope) \u001B[38;5;241m/\u001B[39m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduce_max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnoise\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m prop \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mrepeat, (ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mexpand_dims, (ag__\u001B[38;5;241m.\u001B[39mld(prop),), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), fscope), ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(tf)\u001B[38;5;241m.\u001B[39mshape, (ag__\u001B[38;5;241m.\u001B[39mld(audio),), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)[\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28mdict\u001B[39m(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), fscope)\n\u001B[0;32m     24\u001B[0m audio \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(audio) \u001B[38;5;241m+\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(noise) \u001B[38;5;241m*\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(prop) \u001B[38;5;241m*\u001B[39m ag__\u001B[38;5;241m.\u001B[39mld(scale)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001B[0m, in \u001B[0;36mconverted_call\u001B[1;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_in_allowlist_cache(f, options):\n\u001B[0;32m    330\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: from cache\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n\u001B[1;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ag_ctx\u001B[38;5;241m.\u001B[39mcontrol_status_ctx()\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m ag_ctx\u001B[38;5;241m.\u001B[39mStatus\u001B[38;5;241m.\u001B[39mDISABLED:\n\u001B[0;32m    334\u001B[0m   logging\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAllowlisted: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: AutoGraph is disabled in context\u001B[39m\u001B[38;5;124m'\u001B[39m, f)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[1;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[0;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1751\u001B[0m, in \u001B[0;36m_create_c_op\u001B[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001B[0m\n\u001B[0;32m   1748\u001B[0m   c_op \u001B[38;5;241m=\u001B[39m pywrap_tf_session\u001B[38;5;241m.\u001B[39mTF_FinishOperation(op_desc)\n\u001B[0;32m   1749\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mInvalidArgumentError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1750\u001B[0m   \u001B[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001B[39;00m\n\u001B[1;32m-> 1751\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(e\u001B[38;5;241m.\u001B[39mmessage)\n\u001B[0;32m   1753\u001B[0m \u001B[38;5;66;03m# Record the current Python stack trace as the creating stacktrace of this\u001B[39;00m\n\u001B[0;32m   1754\u001B[0m \u001B[38;5;66;03m# TF_Operation.\u001B[39;00m\n\u001B[0;32m   1755\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extract_traceback:\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4624\\4097213244.py\", line 3, in None  *\n        lambda x, y: (add_noise(x, noises, scale=scale), y)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_4624\\1548865019.py\", line 8, in add_noise  *\n        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n\n    ValueError: Invalid reduction dimension 1 for input with 1 dimensions. for '{{node Max_1}} = Max[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](GatherV2, Max_1/reduction_indices)' with input shapes: [?], [] and with computed input tensors: input[1] = <1>.\n"
     ]
    }
   ],
   "source": [
    "# Add noise to the training set\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (add_noise(x, noises, scale=scale), y),\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    ")\n",
    "\n",
    "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
    "train_ds = train_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.map(\n",
    "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "valid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:23.448952900Z",
     "start_time": "2023-09-14T19:16:19.617467300Z"
    }
   },
   "id": "94cdc5f4c1b57be4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-14T19:16:23.448952900Z"
    }
   },
   "id": "2896650f1e0d969d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input (InputLayer)          [(None, 16000, 1)]           0         []                            \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 16000, 128)           512       ['input[0][0]']               \n",
      "                                                                                                  \n",
      " activation_10 (Activation)  (None, 16000, 128)           0         ['conv1d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 16000, 128)           49280     ['activation_10[0][0]']       \n",
      "                                                                                                  \n",
      " activation_11 (Activation)  (None, 16000, 128)           0         ['conv1d_17[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 16000, 128)           49280     ['activation_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 16000, 128)           256       ['input[0][0]']               \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 16000, 128)           0         ['conv1d_18[0][0]',           \n",
      "                                                                     'conv1d_15[0][0]']           \n",
      "                                                                                                  \n",
      " activation_12 (Activation)  (None, 16000, 128)           0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPoolin  (None, 8000, 128)            0         ['activation_12[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " average_pooling1d (Average  (None, 2666, 128)            0         ['max_pooling1d_4[0][0]']     \n",
      " Pooling1D)                                                                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 341248)               0         ['average_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  8735974   ['flatten[0][0]']             \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " output (Dense)              (None, 8)                    1032      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 87493000 (333.76 MB)\n",
      "Trainable params: 87493000 (333.76 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def residual_block(x, filters, conv_num = 3, activation = \"relu\"):\n",
    "    s = keras.layers.Conv1D(filters, 1, padding = \"same\")(x)\n",
    "    \n",
    "    for i in range(conv_num - 1):\n",
    "        x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "        x = keras.layers.Activation(activation)(x)\n",
    "    \n",
    "    x = keras.layers.Conv1D(filters, 3, padding = \"same\")(x)\n",
    "    x = keras.layers.Add()([x, s])\n",
    "    x = keras.layers.Activation(activation)(x)\n",
    "    \n",
    "    return keras.layers.MaxPool1D(pool_size = 2, strides = 2)(x)\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = keras.layers.Input(shape = input_shape, name = \"input\")\n",
    "    \n",
    "    # Adjust the Conv1D layer to accept the new input shape\n",
    "    x = keras.layers.Conv1D(16, 3, padding=\"same\")(inputs)\n",
    "    \n",
    "    x = residual_block(inputs, 16, 2)\n",
    "    x = residual_block(inputs, 32, 2)\n",
    "    x = residual_block(inputs, 64, 3)\n",
    "    x = residual_block(inputs, 128, 3)\n",
    "    x = residual_block(inputs, 128, 3)\n",
    "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(num_classes, activation = \"softmax\", name = \"output\")(x)\n",
    "    \n",
    "    return keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "\n",
    "# Define the new input shape (16000 samples)\n",
    "new_input_shape = (16000, 1)\n",
    "\n",
    "# Build the model with the new input shape\n",
    "model = build_model(new_input_shape, len(class_names))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "\n",
    "model_save_filename = \"model.h5\"\n",
    "\n",
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(model_save_filename, monitor=\"val_accuracy\", save_best_only=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T19:16:34.639126300Z",
     "start_time": "2023-09-14T19:16:33.073162300Z"
    }
   },
   "id": "4636701f39d74f8c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9899 - accuracy: 0.5830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 900s 5s/step - loss: 0.9899 - accuracy: 0.5830 - val_loss: 0.6222 - val_accuracy: 0.7027\n",
      "Epoch 2/8\n",
      "169/169 [==============================] - 875s 5s/step - loss: 0.4164 - accuracy: 0.8271 - val_loss: 0.4138 - val_accuracy: 0.8307\n",
      "Epoch 3/8\n",
      "169/169 [==============================] - 941s 6s/step - loss: 0.2708 - accuracy: 0.8871 - val_loss: 0.3854 - val_accuracy: 0.8493\n",
      "Epoch 4/8\n",
      "169/169 [==============================] - 926s 5s/step - loss: 0.1793 - accuracy: 0.9314 - val_loss: 0.4613 - val_accuracy: 0.8400\n",
      "Epoch 5/8\n",
      "  8/169 [>.............................] - ETA: 14:31 - loss: 0.1136 - accuracy: 0.9594"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearlystopping_cb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmdlcheckpoint_cb\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1734\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1735\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1736\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1739\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1740\u001B[0m ):\n\u001B[0;32m   1741\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1742\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1744\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    854\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    855\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    856\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 857\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    859\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    860\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    861\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    146\u001B[0m   (concrete_function,\n\u001B[0;32m    147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs)\u001B[0m\n\u001B[0;32m   1345\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1347\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1348\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1349\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1350\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1351\u001B[0m     args,\n\u001B[0;32m   1352\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1353\u001B[0m     executing_eagerly)\n\u001B[0;32m   1354\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[0;32m    195\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[1;32m--> 196\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    202\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mlist\u001B[39m(args))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001B[0m, in \u001B[0;36mContext.call_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1455\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[0;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1457\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1460\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1461\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1462\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1463\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1465\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m   1466\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m   1467\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1471\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[0;32m   1472\u001B[0m   )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T20:18:10.425052600Z",
     "start_time": "2023-09-14T19:16:36.401299100Z"
    }
   },
   "id": "281114c339294ae7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Accuracy of model:\",model.evaluate(valid_ds))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34fd57e16768a582"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
